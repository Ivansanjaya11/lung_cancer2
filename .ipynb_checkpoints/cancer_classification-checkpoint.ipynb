{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d426258-2e34-448b-9eab-5a5c08b3cb24",
   "metadata": {},
   "source": [
    "proposed models: mobilenet, mobilenetv2, mobilenetv3, nasnetmobile, efficientnetv2b0, efficientnetlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb92736-67cf-4b6a-a3b3-126d0d45b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import seaborn as sns\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn import metrics\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours, NearMiss\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.applications import ResNet50V2, InceptionResNetV2, NASNetMobile, MobileNet\n",
    "from tensorflow.keras.applications import EfficientNetV2B0, EfficientNetV2B1, EfficientNetV2B2, EfficientNetV2B3\n",
    "from tensorflow.keras.applications import DenseNet121, DenseNet169, DenseNet201\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "from keras.regularizers import l2\n",
    "import keras_tuner as kt\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "num_classes=4\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "categories = [\"adenocarcinoma\", \"large_cell_carcinoma\", \"normal\", \"squamous_cell_carcinoma\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0909c566-1ab5-4b2d-ae3f-c8f594812fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN data\n",
    "\n",
    "directory_train = r\"lung_classification_dataset\\train\"\n",
    "\n",
    "adenocarcinoma_dir = directory_train + \"/\" + categories[0]\n",
    "large_cell_carcinoma_dir = directory_train + \"/\" + categories[1]\n",
    "normal_dir = directory_train + \"/\" + categories[2]\n",
    "squamos_cell_carcinoma_dir = directory_train + \"/\" + categories[3]\n",
    "\n",
    "path_list_train = []\n",
    "category_list_train = []\n",
    "for category in categories:\n",
    "    folder_path = os.path.join(directory_train, category)\n",
    "    folder_image_contents = os.listdir(folder_path)\n",
    "    for image_file in folder_image_contents:\n",
    "        image_file_path = os.path.join(folder_path, image_file)\n",
    "        path_list_train.append(image_file_path)\n",
    "        category_list_train.append(category)\n",
    "\n",
    "path_series_train = pd.Series(path_list_train, name=\"filepath\")\n",
    "category_series_train = pd.Series(category_list_train, name=\"category\")\n",
    "\n",
    "image_paths_train_df = pd.DataFrame(path_series_train).join(category_series_train)\n",
    "\n",
    "#print(image_paths_train_df.head())   \n",
    "\n",
    "# VAL data\n",
    "directory_val = r\"lung_classification_dataset\\valid\"\n",
    "\n",
    "adenocarcinoma_dir = directory_val + \"/\" + categories[0]\n",
    "large_cell_carcinoma_dir = directory_val + \"/\" + categories[1]\n",
    "normal_dir = directory_val + \"/\" + categories[2]\n",
    "squamos_cell_carcinoma_dir = directory_val + \"/\" + categories[3]\n",
    "\n",
    "path_list_val = []\n",
    "category_list_val = []\n",
    "for category in categories:\n",
    "    folder_path = os.path.join(directory_val, category)\n",
    "    folder_image_contents = os.listdir(folder_path)\n",
    "    for image_file in folder_image_contents:\n",
    "        image_file_path = os.path.join(folder_path, image_file)\n",
    "        path_list_val.append(image_file_path)\n",
    "        category_list_val.append(category)\n",
    "\n",
    "path_series_val = pd.Series(path_list_val, name=\"filepath\")\n",
    "category_series_val = pd.Series(category_list_val, name=\"category\")\n",
    "\n",
    "image_paths_val_df = pd.DataFrame(path_series_val).join(category_series_val)\n",
    "\n",
    "#print(image_paths_val_df.head())\n",
    "\n",
    "# TEST data\n",
    "directory_test = r\"lung_classification_dataset\\test\"\n",
    "\n",
    "adenocarcinoma_dir = directory_test + \"/\" + categories[0]\n",
    "large_cell_carcinoma_dir = directory_test + \"/\" + categories[1]\n",
    "normal_dir = directory_test + \"/\" + categories[2]\n",
    "squamos_cell_carcinoma_dir = directory_test + \"/\" + categories[3]\n",
    "\n",
    "path_list_test = []\n",
    "category_list_test = []\n",
    "for category in categories:\n",
    "    folder_path = os.path.join(directory_test, category)\n",
    "    folder_image_contents = os.listdir(folder_path)\n",
    "    for image_file in folder_image_contents:\n",
    "        image_file_path = os.path.join(folder_path, image_file)\n",
    "        path_list_test.append(image_file_path)\n",
    "        category_list_test.append(category)\n",
    "\n",
    "path_series_test = pd.Series(path_list_test, name=\"filepath\")\n",
    "category_series_test = pd.Series(category_list_test, name=\"category\")\n",
    "\n",
    "image_paths_test_df = pd.DataFrame(path_series_test).join(category_series_test)\n",
    "\n",
    "#print(image_paths_test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb24c56-1a84-4656-aa0e-b8abaa5b14c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Image resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11f0e1d-58a4-4b4d-9348-32022d420471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN data\n",
    "size_data_train = {}\n",
    "is_grayscale = 0 # enter 0 for color, 1 for grayscale\n",
    "for category in categories:\n",
    "    folder_path = os.path.join(directory_train, category)\n",
    "    folder_image_contents = os.listdir(folder_path)\n",
    "    image_sizes_in_one_category = {}\n",
    "    for image_file in folder_image_contents:\n",
    "        image_file_path = os.path.join(folder_path, image_file)\n",
    "        img = cv2.imread(image_file_path)\n",
    "        height, width, channel = img.shape\n",
    "        if(str(height) + \" x \" + str(width) in image_sizes_in_one_category):\n",
    "            image_sizes_in_one_category[str(height) + \" x \" + str(width)] += 1\n",
    "        else:\n",
    "            image_sizes_in_one_category[str(height) + \" x \" + str(width)] = 1\n",
    "    #plt.imshow(cv2.imread(image_file_path, is_grayscale))\n",
    "    #plt.show()\n",
    "    size_data_train[category] = image_sizes_in_one_category\n",
    "size_data_train_df = pd.DataFrame(size_data_train)\n",
    "#print(size_data_train)\n",
    "#print(size_data_train_df.head(10))\n",
    "\n",
    "# VAL data\n",
    "size_data_val = {}\n",
    "is_grayscale = 0 # enter 0 for color, 1 for grayscale\n",
    "for category in categories:\n",
    "    folder_path = os.path.join(directory_val, category)\n",
    "    folder_image_contents = os.listdir(folder_path)\n",
    "    image_sizes_in_one_category = {}\n",
    "    for image_file in folder_image_contents:\n",
    "        image_file_path = os.path.join(folder_path, image_file)\n",
    "        img = cv2.imread(image_file_path)\n",
    "        height, width, channel = img.shape\n",
    "        if(str(height) + \" x \" + str(width) in image_sizes_in_one_category):\n",
    "            image_sizes_in_one_category[str(height) + \" x \" + str(width)] += 1\n",
    "        else:\n",
    "            image_sizes_in_one_category[str(height) + \" x \" + str(width)] = 1\n",
    "    #plt.imshow(cv2.imread(image_file_path, is_grayscale))\n",
    "    #plt.show()\n",
    "    size_data_val[category] = image_sizes_in_one_category\n",
    "size_data_val_df = pd.DataFrame(size_data_val)\n",
    "#print(size_data_val)\n",
    "#print(size_data_val_df.head(10))\n",
    "\n",
    "# TEST data\n",
    "size_data_test = {}\n",
    "is_grayscale = 0 # enter 0 for color, 1 for grayscale\n",
    "for category in categories:\n",
    "    folder_path = os.path.join(directory_test, category)\n",
    "    folder_image_contents = os.listdir(folder_path)\n",
    "    image_sizes_in_one_category = {}\n",
    "    for image_file in folder_image_contents:\n",
    "        image_file_path = os.path.join(folder_path, image_file)\n",
    "        img = cv2.imread(image_file_path)\n",
    "        height, width, channel = img.shape\n",
    "        if(str(height) + \" x \" + str(width) in image_sizes_in_one_category):\n",
    "            image_sizes_in_one_category[str(height) + \" x \" + str(width)] += 1\n",
    "        else:\n",
    "            image_sizes_in_one_category[str(height) + \" x \" + str(width)] = 1\n",
    "    #plt.imshow(cv2.imread(image_file_path, is_grayscale))\n",
    "    #plt.show()\n",
    "    size_data_test[category] = image_sizes_in_one_category\n",
    "size_data_test_df = pd.DataFrame(size_data_test)\n",
    "#print(size_data_test)\n",
    "#print(size_data_test_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e7b015-e2b2-4457-8405-9accdbc66004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN data\n",
    "\n",
    "dataset_train = []\n",
    "desired_size = 256\n",
    "for index, row in image_paths_train_df.iterrows():\n",
    "    filepath = row[\"filepath\"]\n",
    "    img = cv2.imread(filepath, is_grayscale)\n",
    "    img = cv2.resize(img, (desired_size, desired_size))\n",
    "    label = row[\"category\"]\n",
    "    dataset_train.append([img, label])\n",
    "    \n",
    "random.shuffle(dataset_train)\n",
    "\n",
    "#print(dataset_train[0][0].shape)\n",
    "#print(dataset_train[0][1])\n",
    "#plt.imshow(dataset_train[0][0])\n",
    "#plt.show()\n",
    "\n",
    "# VAL data\n",
    "\n",
    "dataset_val = []\n",
    "desired_size = 256\n",
    "for index, row in image_paths_val_df.iterrows():\n",
    "    filepath = row[\"filepath\"]\n",
    "    img = cv2.imread(filepath, is_grayscale)\n",
    "    img = cv2.resize(img, (desired_size, desired_size))\n",
    "    label = row[\"category\"]\n",
    "    dataset_val.append([img, label])\n",
    "    \n",
    "random.shuffle(dataset_val)\n",
    "\n",
    "#print(dataset_val[0][0].shape)\n",
    "#print(dataset_val[0][1])\n",
    "#plt.imshow(dataset_val[0][0])\n",
    "#plt.show()\n",
    "\n",
    "# TEST data\n",
    "\n",
    "dataset_test = []\n",
    "desired_size = 256\n",
    "for index, row in image_paths_test_df.iterrows():\n",
    "    filepath = row[\"filepath\"]\n",
    "    img = cv2.imread(filepath, is_grayscale)\n",
    "    img = cv2.resize(img, (desired_size, desired_size))\n",
    "    label = row[\"category\"]\n",
    "    dataset_test.append([img, label])\n",
    "    \n",
    "random.shuffle(dataset_test)\n",
    "\n",
    "#print(dataset_test[0][0].shape)\n",
    "#print(dataset_test[0][1])\n",
    "#plt.imshow(dataset_test[0][0])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4ae7cf-a57b-4faa-8a46-ba54075168f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Histogram Equilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfbba53-99f4-44b3-a35e-2aa45a816277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN data\n",
    "for data in dataset_train:\n",
    "    img = cv2.equalizeHist(data[0])\n",
    "    data[0] = img\n",
    "\n",
    "# VAL data\n",
    "for data in dataset_val:\n",
    "    img = cv2.equalizeHist(data[0])\n",
    "    data[0] = img\n",
    "\n",
    "# TEST data\n",
    "for data in dataset_test:\n",
    "    img = cv2.equalizeHist(data[0])\n",
    "    data[0] = img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf20e685-aed8-42e6-a1f4-5f7879eacaf6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Image smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660dd876-a00e-41a4-ac99-177f7388662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using bilateral filtering\n",
    "diameter = 3\n",
    "sigma_color = 25\n",
    "sigma_space = 25\n",
    "\n",
    "# TRAIN data\n",
    "for data in dataset_train:\n",
    "    img = cv2.bilateralFilter(data[0], diameter, sigma_color, sigma_space)\n",
    "    data[0] = img\n",
    "\n",
    "#plt.imshow(dataset_train[0][0])\n",
    "#plt.show()\n",
    "\n",
    "# VAL data\n",
    "for data in dataset_val:\n",
    "    img = cv2.bilateralFilter(data[0], diameter, sigma_color, sigma_space)\n",
    "    data[0] = img\n",
    "\n",
    "#plt.imshow(dataset_val[0][0])\n",
    "#plt.show()\n",
    "\n",
    "# TEST data\n",
    "for data in dataset_test:\n",
    "    img = cv2.bilateralFilter(data[0], diameter, sigma_color, sigma_space)\n",
    "    data[0] = img\n",
    "\n",
    "#plt.imshow(dataset_test[0][0])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a495a95f-82d1-4f3d-b4bb-3a3050629147",
   "metadata": {},
   "source": [
    "# Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae1b0d0-8818-4ce8-b3c0-e2ed7cab97ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using min-max scaling\n",
    "\n",
    "# TRAIN data\n",
    "for data in dataset_train:\n",
    "    img = data[0]/255.0\n",
    "    data[0] = img\n",
    "\n",
    "#plt.imshow(dataset_train[0][0])\n",
    "#plt.show()\n",
    "\n",
    "# VAL data\n",
    "for data in dataset_val:\n",
    "    img = data[0]/255.0\n",
    "    data[0] = img\n",
    "\n",
    "#plt.imshow(dataset_val[0][0])\n",
    "#plt.show()\n",
    "\n",
    "# TEST data\n",
    "for data in dataset_test:\n",
    "    img = data[0]/255.0\n",
    "    data[0] = img\n",
    "\n",
    "#plt.imshow(dataset_test[0][0])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c75101-ca28-4942-b6dc-a232475733a8",
   "metadata": {},
   "source": [
    "# Morphological operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab29fc7-d25f-442a-92ab-657916eec228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN data\n",
    "for data in dataset_train:\n",
    "    binr = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    invert = cv2.bitwise_not(binr)\n",
    "    erosion = cv2.erode(invert, kernel, iterations=1)\n",
    "\n",
    "# VAL data\n",
    "for data in dataset_val:\n",
    "    binr = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    invert = cv2.bitwise_not(binr)\n",
    "    erosion = cv2.erode(invert, kernel, iterations=1)\n",
    "\n",
    "# TEST data\n",
    "for data in dataset_test:\n",
    "    binr = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    invert = cv2.bitwise_not(binr)\n",
    "    erosion = cv2.erode(invert, kernel, iterations=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a468f39-abb2-4f02-9f5b-cbec26b64326",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a27a17-6185-4862-8a49-096774a87433",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = [], []\n",
    "x_val, y_val = [], []\n",
    "x_test, y_test = [], []\n",
    "\n",
    "for image, category in dataset_train:\n",
    "    x_train.append(image)\n",
    "    y_train.append(category)\n",
    "\n",
    "for image, category in dataset_val:\n",
    "    x_val.append(image)\n",
    "    y_val.append(category)\n",
    "\n",
    "for image, category in dataset_test:\n",
    "    x_test.append(image)\n",
    "    y_test.append(category)\n",
    "\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# apply one-hot encoding\n",
    "\n",
    "y_val = to_categorical(y_val, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "for i in range(0, len(label_encoder.classes_)):\n",
    "    print(i, end=\"\")\n",
    "    print(\" = \", end=\"\")\n",
    "    print(label_encoder.classes_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592e2b1f-d3ba-4e57-abd7-ead56d38ca14",
   "metadata": {},
   "source": [
    "# Handling data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96dd02e-2595-481c-b609-ad5e9e92ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use data augmentation (albumentation library)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
